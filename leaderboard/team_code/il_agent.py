#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
IL Agent - ä½¿ç”¨ILè®­ç»ƒçš„æ¨¡å‹
"""

import os
import sys
import numpy as np
import torch
import torch.nn as nn
from PIL import Image
import carla

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/home/ajifang/b2drive')
sys.path.append('/home/ajifang/b2drive/rl_ppo_model')

from leaderboard.autoagents import autonomous_agent


class SimplePolicyNetwork(nn.Module):
    """
    ç®€åŒ–çš„ç­–ç•¥ç½‘ç»œï¼ˆå’Œè®­ç»ƒæ—¶ä½¿ç”¨çš„ä¸€è‡´ï¼‰
    """

    def __init__(self, image_channels=3, state_dim=6, action_dim=3, hidden_dims=[512, 256]):
        super().__init__()

        # å›¾åƒç¼–ç å™¨
        self.image_encoder = nn.Sequential(
            nn.Conv2d(image_channels, 32, 5, stride=2, padding=2),
            nn.ReLU(),
            nn.Conv2d(32, 64, 5, stride=2, padding=2),
            nn.ReLU(),
            nn.Conv2d(64, 128, 5, stride=2, padding=2),
            nn.ReLU(),
            nn.Conv2d(128, 256, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1))
        )

        # MLPå±‚
        self.fc = nn.Sequential(
            nn.Linear(256 + state_dim, hidden_dims[0]),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(hidden_dims[0], hidden_dims[1]),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(hidden_dims[1], action_dim),
            nn.Sigmoid()
        )

    def forward(self, image, state):
        # ç¼–ç å›¾åƒ
        img_features = self.image_encoder(image)
        img_features = img_features.view(img_features.size(0), -1)

        # æ‹¼æ¥ç‰¹å¾
        combined = torch.cat([img_features, state], dim=1)

        # é¢„æµ‹åŠ¨ä½œ
        action = self.fc(combined)

        # è°ƒæ•´steerèŒƒå›´åˆ°[-1, 1]
        throttle = action[:, 0:1]
        steer = action[:, 1:2] * 2 - 1
        brake = action[:, 2:3]

        return torch.cat([throttle, steer, brake], dim=1)


class ILAgent(autonomous_agent.AutonomousAgent):
    """
    ILè®­ç»ƒçš„é©¾é©¶agent
    ä½¿ç”¨è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œè¿›è¡Œå†³ç­–
    """

    def setup(self, path_to_conf_file):
        """
        åˆå§‹åŒ–agent
        Args:
            path_to_conf_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆè¿™é‡Œä¸ä½¿ç”¨ï¼Œä½¿ç”¨ç¡¬ç¼–ç çš„æ¨¡å‹è·¯å¾„ï¼‰
        """
        print("=" * 70)
        print("ğŸ¤– åˆå§‹åŒ–IL Agent")
        print("=" * 70)

        # è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {self.device}")

        # æ¨¡å‹è·¯å¾„
        self.model_path = '/home/ajifang/b2drive/rl_ppo_model/checkpoints/best_model.pth'

        # åˆ›å»ºç½‘ç»œ
        print("ğŸ—ï¸  åˆ›å»ºç­–ç•¥ç½‘ç»œ...")
        self.policy_network = SimplePolicyNetwork(
            image_channels=3,
            state_dim=6,
            action_dim=3,
            hidden_dims=[512, 256]
        ).to(self.device)

        # åŠ è½½æƒé‡
        print(f"ğŸ“‚ åŠ è½½æƒé‡: {self.model_path}")
        if os.path.exists(self.model_path):
            checkpoint = torch.load(self.model_path, map_location=self.device)
            self.policy_network.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ… æƒé‡åŠ è½½æˆåŠŸ (Epoch {checkpoint.get('epoch', 'N/A')}, Loss {checkpoint.get('loss', 'N/A'):.6f})")
        else:
            print(f"âš ï¸  è­¦å‘Š: æƒé‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")

        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        self.policy_network.eval()

        # å›¾åƒé¢„å¤„ç†å‚æ•°
        self.image_size = (224, 224)

        # çŠ¶æ€ä¿¡æ¯
        self.speed = 0.0
        self.position = None
        self.rotation = None

        # ç›®æ ‡ç‚¹ä¿¡æ¯ï¼ˆä»GPSè·å–ï¼‰
        self.target_x = 0.0
        self.target_y = 0.0

        print("=" * 70)
        print("âœ… IL Agentåˆå§‹åŒ–å®Œæˆ")
        print("=" * 70)
        print()

    def sensors(self):
        """
        å®šä¹‰agentéœ€è¦çš„ä¼ æ„Ÿå™¨
        Returns:
            ä¼ æ„Ÿå™¨é…ç½®åˆ—è¡¨
        """
        sensors = [
            # RGBå‰ç½®ç›¸æœº
            {
                'type': 'sensor.camera.rgb',
                'id': 'rgb_front',
                'x': 1.3, 'y': 0.0, 'z': 2.3,
                'roll': 0.0, 'pitch': 0.0, 'yaw': 0.0,
                'width': 1600, 'height': 900, 'fov': 100
            },
            # GNSS
            {
                'type': 'sensor.other.gnss',
                'id': 'gps',
                'x': 0.0, 'y': 0.0, 'z': 0.0,
                'roll': 0.0, 'pitch': 0.0, 'yaw': 0.0
            },
            # IMU
            {
                'type': 'sensor.other.imu',
                'id': 'imu',
                'x': 0.0, 'y': 0.0, 'z': 0.0,
                'roll': 0.0, 'pitch': 0.0, 'yaw': 0.0
            },
            # é€Ÿåº¦è®¡
            {
                'type': 'sensor.speedometer',
                'id': 'speed',
                'x': 0.0, 'y': 0.0, 'z': 0.0,
                'roll': 0.0, 'pitch': 0.0, 'yaw': 0.0
            }
        ]
        return sensors

    def run_step(self, input_data, timestamp):
        """
        æ‰§è¡Œä¸€æ­¥å†³ç­–
        Args:
            input_data: ä¼ æ„Ÿå™¨æ•°æ®å­—å…¸
            timestamp: å½“å‰æ—¶é—´æˆ³
        Returns:
            carla.VehicleControl: è½¦è¾†æ§åˆ¶æŒ‡ä»¤
        """
        # 1. è·å–ä¼ æ„Ÿå™¨æ•°æ®
        rgb_front = input_data.get('rgb_front', None)
        gps_data = input_data.get('gps', None)
        imu_data = input_data.get('imu', None)
        speed_data = input_data.get('speed', None)

        if rgb_front is None:
            print("âš ï¸  è­¦å‘Š: æ²¡æœ‰RGBå›¾åƒæ•°æ®")
            return carla.VehicleControl()

        # 2. å¤„ç†å›¾åƒ
        image = rgb_front[1][:, :, :3]  # (H, W, 3)
        image = Image.fromarray(image)
        image = image.resize(self.image_size)
        image = np.array(image, dtype=np.float32) / 255.0
        image = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)  # (1, 3, H, W)
        image = image.to(self.device)

        # 3. å¤„ç†çŠ¶æ€ä¿¡æ¯
        # é€Ÿåº¦
        if speed_data is not None:
            self.speed = speed_data[1]['speed']

        # GPSä½ç½®
        if gps_data is not None:
            gps = gps_data[1]
            self.position = (gps[0], gps[1])  # (lat, lon)

        # IMUå§¿æ€
        if imu_data is not None:
            imu = imu_data[1]
            self.rotation = imu[-1]  # yaw

        # è·å–ç›®æ ‡ç‚¹ï¼ˆä»_command_plannerï¼‰
        if hasattr(self, '_command_planner') and self._command_planner is not None:
            target_location = self._command_planner.target_location
            if target_location is not None:
                self.target_x = target_location.x
                self.target_y = target_location.y

        # æ„é€ çŠ¶æ€å‘é‡
        state = torch.tensor([
            self.speed / 10.0,  # å½’ä¸€åŒ–é€Ÿåº¦
            0.0,  # x (æš‚æ—¶ç”¨0)
            0.0,  # y (æš‚æ—¶ç”¨0)
            self.rotation if self.rotation is not None else 0.0,
            self.target_x / 100.0,  # å½’ä¸€åŒ–ç›®æ ‡x
            self.target_y / 100.0,  # å½’ä¸€åŒ–ç›®æ ‡y
        ], dtype=torch.float32).unsqueeze(0).to(self.device)

        # 4. æ¨¡å‹æ¨ç†
        with torch.no_grad():
            action = self.policy_network(image, state)
            action = action.cpu().numpy()[0]  # (3,)

        throttle = float(action[0])
        steer = float(action[1])
        brake = float(action[2])

        # 5. åˆ›å»ºæ§åˆ¶æŒ‡ä»¤
        control = carla.VehicleControl()
        control.throttle = np.clip(throttle, 0.0, 1.0)
        control.steer = np.clip(steer, -1.0, 1.0)
        control.brake = np.clip(brake, 0.0, 1.0)
        control.hand_brake = False
        control.manual_gear_shift = False

        return control

    def destroy(self):
        """
        æ¸…ç†èµ„æº
        """
        print("ğŸ§¹ IL Agentæ¸…ç†å®Œæˆ")
        del self.policy_network


def get_entry_point():
    """
    B2Dæ¡†æ¶è¦æ±‚çš„å…¥å£å‡½æ•°
    """
    return 'ILAgent'
