#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
B2Dæ•°æ®é›†åŠ è½½å™¨ - ç”¨äºRLè®­ç»ƒ
è¯»å–å›¾åƒå’Œä¸“å®¶åŠ¨ä½œ
"""

import os
import glob
import gzip
import json
import numpy as np
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
import tarfile
from pathlib import Path


class B2DDataset(Dataset):
    """
    B2Dæ•°æ®é›†åŠ è½½å™¨

    æ•°æ®ç»“æ„ï¼š
    - camera/rgb_front/*.jpg - RGBå‰ç½®ç›¸æœºå›¾åƒ
    - anno/*.json.gz - ä¸“å®¶åŠ¨ä½œå’Œè½¦è¾†çŠ¶æ€
    """

    def __init__(self, data_root, image_size=(224, 224), max_clips=None):
        """
        Args:
            data_root: æ•°æ®æ ¹ç›®å½•ï¼ˆåŒ…å«è§£å‹åçš„clipsï¼‰
            image_size: å›¾åƒresizeå¤§å°
            max_clips: æœ€å¤§ä½¿ç”¨çš„clipsæ•°é‡ï¼ˆNone=ä½¿ç”¨å…¨éƒ¨ï¼‰
        """
        self.data_root = Path(data_root)
        self.image_size = image_size

        print(f"ğŸ” æ­£åœ¨æ‰«ææ•°æ®é›†: {data_root}")

        # æŸ¥æ‰¾æ‰€æœ‰å·²è§£å‹çš„clipç›®å½•
        self.clip_dirs = []
        for clip_dir in sorted(self.data_root.glob("*")):
            if clip_dir.is_dir() and not clip_dir.name.endswith('.tar.gz'):
                # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„å­ç›®å½•
                if (clip_dir / "camera" / "rgb_front").exists() and \
                   (clip_dir / "anno").exists():
                    self.clip_dirs.append(clip_dir)

        if max_clips:
            self.clip_dirs = self.clip_dirs[:max_clips]

        print(f"âœ… æ‰¾åˆ° {len(self.clip_dirs)} ä¸ªclips")

        # æ„å»ºæ‰€æœ‰å¸§çš„ç´¢å¼•
        self.samples = []
        for clip_dir in self.clip_dirs:
            # è·å–è¯¥clipçš„æ‰€æœ‰å¸§
            anno_files = sorted((clip_dir / "anno").glob("*.json.gz"))

            for anno_file in anno_files:
                # anno_file.stem è¿”å› "00000.json"ï¼Œéœ€è¦å»æ‰ .json
                frame_id = anno_file.stem.replace('.json', '')  # ä¾‹å¦‚ "00000"
                img_file = clip_dir / "camera" / "rgb_front" / f"{frame_id}.jpg"

                if img_file.exists():
                    self.samples.append({
                        'clip_dir': clip_dir,
                        'frame_id': frame_id,
                        'img_file': img_file,
                        'anno_file': anno_file
                    })

        print(f"âœ… æ€»å…± {len(self.samples)} ä¸ªè®­ç»ƒæ ·æœ¬")

        if len(self.samples) == 0:
            raise ValueError("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è®­ç»ƒæ ·æœ¬ï¼è¯·æ£€æŸ¥æ•°æ®æ˜¯å¦å·²è§£å‹ã€‚")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        sample = self.samples[idx]

        # 1. è¯»å–å›¾åƒ
        img = Image.open(sample['img_file']).convert('RGB')
        img = img.resize(self.image_size)
        img = np.array(img, dtype=np.float32) / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]
        img = torch.from_numpy(img).permute(2, 0, 1)  # HWC -> CHW

        # 2. è¯»å–æ ‡æ³¨ï¼ˆä¸“å®¶åŠ¨ä½œå’ŒçŠ¶æ€ï¼‰
        with gzip.open(sample['anno_file'], 'rt') as f:
            anno = json.load(f)

        # 3. æå–çŠ¶æ€ï¼ˆä½œä¸ºRLçš„observationï¼‰
        state = torch.tensor([
            anno['speed'],           # é€Ÿåº¦
            anno['x'],               # Xåæ ‡
            anno['y'],               # Yåæ ‡
            anno['theta'],           # èˆªå‘è§’
            anno['x_command_far'],   # ç›®æ ‡X
            anno['y_command_far'],   # ç›®æ ‡Y
        ], dtype=torch.float32)

        # 4. æå–ä¸“å®¶åŠ¨ä½œï¼ˆä½œä¸ºRLçš„expert actionï¼‰
        action = torch.tensor([
            anno['throttle'],  # æ²¹é—¨ [0, 1]
            anno['steer'],     # è½¬å‘ [-1, 1]
            anno['brake'],     # åˆ¹è½¦ [0, 1]
        ], dtype=torch.float32)

        return {
            'image': img,           # (3, H, W)
            'state': state,         # (6,)
            'action': action,       # (3,) - ä¸“å®¶åŠ¨ä½œ
            'frame_id': sample['frame_id'],
            'clip_name': sample['clip_dir'].name
        }


def create_dataloader(data_root, batch_size=32, image_size=(224, 224),
                     num_workers=4, shuffle=True, max_clips=None):
    """
    åˆ›å»ºæ•°æ®åŠ è½½å™¨

    Args:
        data_root: æ•°æ®æ ¹ç›®å½•
        batch_size: batchå¤§å°
        image_size: å›¾åƒå¤§å°
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®
        max_clips: æœ€å¤§clipsæ•°é‡

    Returns:
        DataLoader
    """
    dataset = B2DDataset(
        data_root=data_root,
        image_size=image_size,
        max_clips=max_clips
    )

    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True
    )

    return dataloader


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®åŠ è½½å™¨
    print("="*70)
    print("ğŸ§ª æµ‹è¯•B2Dæ•°æ®åŠ è½½å™¨")
    print("="*70)
    print()

    # æ•°æ®è·¯å¾„ï¼ˆæ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ï¼‰
    data_root = "/home/ajifang/b2drive/Bench2Drive-RL50GB/datasets--rethinklab--Bench2Drive/snapshots"

    # æ‰¾åˆ°snapshotç›®å½•
    import glob
    snapshot_dirs = glob.glob(f"{data_root}/*")
    if snapshot_dirs:
        data_root = snapshot_dirs[0]
        print(f"ğŸ“‚ æ•°æ®ç›®å½•: {data_root}")
    else:
        print("âŒ æ‰¾ä¸åˆ°snapshotç›®å½•")
        exit(1)

    try:
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆå…ˆæµ‹è¯•10ä¸ªclipsï¼‰
        dataloader = create_dataloader(
            data_root=data_root,
            batch_size=4,
            image_size=(224, 224),
            num_workers=2,
            shuffle=True,
            max_clips=10  # æµ‹è¯•æ—¶åªç”¨10ä¸ªclips
        )

        print()
        print("="*70)
        print("ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"   - æ€»æ ·æœ¬æ•°: {len(dataloader.dataset)}")
        print(f"   - Batchæ•°é‡: {len(dataloader)}")
        print(f"   - Batchå¤§å°: {dataloader.batch_size}")
        print("="*70)
        print()

        # æµ‹è¯•åŠ è½½ä¸€ä¸ªbatch
        print("ğŸ”„ æµ‹è¯•åŠ è½½ä¸€ä¸ªbatch...")
        batch = next(iter(dataloader))

        print(f"âœ… åŠ è½½æˆåŠŸ!")
        print(f"   - image shape: {batch['image'].shape}")
        print(f"   - state shape: {batch['state'].shape}")
        print(f"   - action shape: {batch['action'].shape}")
        print()

        print("ğŸ“‹ ç¤ºä¾‹æ•°æ®:")
        print(f"   - Speed: {batch['state'][0, 0]:.4f} m/s")
        print(f"   - Throttle: {batch['action'][0, 0]:.4f}")
        print(f"   - Steer: {batch['action'][0, 1]:.4f}")
        print(f"   - Brake: {batch['action'][0, 2]:.4f}")
        print()

        print("="*70)
        print("ğŸ‰ æ•°æ®åŠ è½½å™¨æµ‹è¯•æˆåŠŸ!")
        print("="*70)

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
